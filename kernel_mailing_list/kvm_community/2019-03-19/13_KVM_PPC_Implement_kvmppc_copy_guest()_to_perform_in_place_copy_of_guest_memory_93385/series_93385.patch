From patchwork Tue Mar 19 04:04:33 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
X-Patchwork-Id: 10858811
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 96B726C2
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:48 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 7B73629289
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:48 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 6E2562943C; Tue, 19 Mar 2019 04:04:48 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 0EB3429289
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:47 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727148AbfCSEEq (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 19 Mar 2019 00:04:46 -0400
Received: from mail-pg1-f195.google.com ([209.85.215.195]:34762 "EHLO
        mail-pg1-f195.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725913AbfCSEEq (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 19 Mar 2019 00:04:46 -0400
Received: by mail-pg1-f195.google.com with SMTP id v12so12949373pgq.1;
        Mon, 18 Mar 2019 21:04:46 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id;
        bh=g1JIVSC1Hgz7a+lPmcRua7QRbeXbwn+HRsBNArd4hh0=;
        b=mSDJcZn6uSTHWe9Ka8FdjS2gKpqgJQRN54GupIwwANmg+wkQ5g63ZoMaeBGnvAOzCo
         A5G8tHLH0sXfq6w1yBbDFeI0XF6o3d6cpvjhDbxFN3UmHmrLJ5/1T4wTTRyNJRvso7ZU
         KBvBno2TaTjTvnk1vjbnqs5MEZRW5BNYyJJ9gn4SIFonGa1T/dJeaSVMfeShgJgdJyip
         P4Ymu6MPJHtYa4eZlSWpX1x1s56/bvYHKCnXqlmlu1CjluXJD4zmQMrJhAC8Zb2G85B0
         O5vVzC8mIkwO+VwPDcYh8WhCh29QQ9uUL5kn6supA6e9/blprjO5WAhoeDaPyOp2QfVt
         VP1g==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id;
        bh=g1JIVSC1Hgz7a+lPmcRua7QRbeXbwn+HRsBNArd4hh0=;
        b=JK4mWB4L1mXFo3X+IjBAHmtQcbfkFhPNTCmbQ4r62rC1tk11jWZbkXqJu/h+f6e3Dn
         O0zzM+xa6oxW13IX8ojz60/b/wQYFu5Vlu6c/hQcukpOm7x1/+pX/C0t5uSPIjB/V0Ym
         n+/WSz2gyQ1anxfpVolPZSG8tKC307PyMs3Kqkj0trPvZkpHkUa+bl9sd1uSUBgwvAkY
         cMcxsaf5OTFKNiqJaGfT3+g9l4BE0xNpfpUBA/BBQekppR5U4TozYi5A2t09EVYxcvZo
         U8XPSpU3Q1nROEmL8TgJK3s2OY0uouC4BynAzH4XelQE45qjHElOGqDABJqfkoLVgnZ/
         CsRg==
X-Gm-Message-State: APjAAAU7hGW+UT1Yu75guVw77FmEp2sq41G3vS2cE9y1HjPurXmtzfZ7
        Oe4AQzfcYYqF2MEqYghtdAHcKv6jFyw=
X-Google-Smtp-Source: 
 APXvYqyYeke9+ikTRF99QUEOpWw8SkvXiW6ea9T8vVdvh04MljDAVQdvwQ8uLFQ+btN145CGA4mUnQ==
X-Received: by 2002:a63:f453:: with SMTP id
 p19mr19931092pgk.232.1552968285607;
        Mon, 18 Mar 2019 21:04:45 -0700 (PDT)
Received: from surajjs2.ozlabs.ibm.com ([122.99.82.10])
        by smtp.gmail.com with ESMTPSA id
 h87sm27650935pfj.20.2019.03.18.21.04.42
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Mon, 18 Mar 2019 21:04:44 -0700 (PDT)
From: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
To: kvm-ppc@vger.kernel.org
Cc: paulus@samba.org, kvm@vger.kernel.org,
        Suraj Jitindar Singh <sjitindarsingh@gmail.com>
Subject: [PATCH 1/3] KVM: PPC: Implement kvmppc_copy_guest() to perform in
 place copy of guest memory
Date: Tue, 19 Mar 2019 15:04:33 +1100
Message-Id: <20190319040435.10716-1-sjitindarsingh@gmail.com>
X-Mailer: git-send-email 2.13.6
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Implement the function kvmppc_copy_guest() to be used to perform a memory
copy from one guest physical address to another of a variable length.

This performs similar functionality as the kvm_read_guest() and
kvm_write_guest() functions, except both addresses point to guest memory.
This performs a copy in place using raw_copy_in_user() to avoid having to
buffer the data.

The guest memory can reside in different memslots and the copy length
can span memslots.

Signed-off-by: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
---
 arch/powerpc/kvm/book3s_hv.c | 69 ++++++++++++++++++++++++++++++++++++++++++++
 1 file changed, 69 insertions(+)

diff --git a/arch/powerpc/kvm/book3s_hv.c b/arch/powerpc/kvm/book3s_hv.c
index ec38576dc685..7179ea783f4f 100644
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@ -814,6 +814,75 @@ static int kvmppc_h_set_mode(struct kvm_vcpu *vcpu, unsigned long mflags,
 	}
 }
 
+static int __kvmppc_copy_guest_page(struct kvm_memory_slot *to_memslot,
+				    gfn_t to_gfn, int to_offset,
+				    struct kvm_memory_slot *from_memslot,
+				    gfn_t from_gfn, int from_offset, int len)
+{
+	int r;
+	unsigned long to_addr, from_addr;
+
+	to_addr = gfn_to_hva_memslot(to_memslot, to_gfn);
+	if (kvm_is_error_hva(to_addr))
+		return -EFAULT;
+	from_addr = gfn_to_hva_memslot(from_memslot, from_gfn);
+	if (kvm_is_error_hva(from_addr))
+		return -EFAULT;
+	r = raw_copy_in_user((void __user *)to_addr + to_offset,
+			     (void __user *)from_addr + from_offset, len);
+	if (r)
+		return -EFAULT;
+	return 0;
+}
+
+static int next_segment_many(unsigned long len, int offset1, int offset2)
+{
+	int size = min(PAGE_SIZE - offset1, PAGE_SIZE - offset2);
+
+	if (len > size)
+		return size;
+	else
+		return len;
+}
+
+static int kvmppc_copy_guest(struct kvm *kvm, gpa_t to, gpa_t from,
+			     unsigned long len)
+{
+	struct kvm_memory_slot *to_memslot = NULL;
+	struct kvm_memory_slot *from_memslot = NULL;
+	gfn_t to_gfn = to >> PAGE_SHIFT;
+	gfn_t from_gfn = from >> PAGE_SHIFT;
+	int seg;
+	int to_offset = offset_in_page(to);
+	int from_offset = offset_in_page(from);
+	int ret;
+
+	while ((seg = next_segment_many(len, to_offset, from_offset)) != 0) {
+		if (!to_memslot || (to_gfn >= (to_memslot->base_gfn +
+					       to_memslot->npages)))
+			to_memslot = gfn_to_memslot(kvm, to_gfn);
+		if (!from_memslot || (from_gfn >= (from_memslot->base_gfn +
+						   from_memslot->npages)))
+			from_memslot = gfn_to_memslot(kvm, from_gfn);
+
+		ret = __kvmppc_copy_guest_page(to_memslot, to_gfn, to_offset,
+					       from_memslot, from_gfn,
+					       from_offset, seg);
+		if (ret < 0)
+			return ret;
+		mark_page_dirty(kvm, to_gfn);
+
+		to_offset = (to_offset + seg) & (PAGE_SIZE - 1);
+		from_offset = (from_offset + seg) & (PAGE_SIZE - 1);
+		len -= seg;
+		if (!to_offset)
+			to_gfn += 1;
+		if (!from_offset)
+			from_gfn += 1;
+	}
+	return 0;
+}
+
 static int kvm_arch_vcpu_yield_to(struct kvm_vcpu *target)
 {
 	struct kvmppc_vcore *vcore = target->arch.vcore;

From patchwork Tue Mar 19 04:04:34 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
X-Patchwork-Id: 10858813
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id C164717E9
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:50 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id A836E29289
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:50 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 9C1A62943C; Tue, 19 Mar 2019 04:04:50 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 41B2429289
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:50 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727376AbfCSEEt (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 19 Mar 2019 00:04:49 -0400
Received: from mail-pf1-f196.google.com ([209.85.210.196]:42715 "EHLO
        mail-pf1-f196.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1725913AbfCSEEt (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 19 Mar 2019 00:04:49 -0400
Received: by mail-pf1-f196.google.com with SMTP id r15so10007025pfn.9;
        Mon, 18 Mar 2019 21:04:48 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=7MN1030302t70DeNGRrKyHcA7xhfX6ZTmVDiGJN+8Rk=;
        b=nThsCMcDXv1ENe/tMWA1EQunG7yPbUwn8yPm7NuiJ4ZWFr4oTXaS2ArHPPsppOLg3m
         rcBufCk+DI5i7Me8qfxaot8IitNbvagWUqoLIHwuHDbUI14XeRMcaoUgsnDv9Tuve/YI
         t+7tmeI9LoMCwXNNMk5WHivewIAJOXvnND9PTjYU51Jq1FWg/cxSBIRKiiHKNyaaaBJa
         0Qta35qfQM/9KlSHdNi503hhtPffqg2r6vs6jyBV2AVCfIJKL6qT/+igibq5UCP7JG4s
         l4Po+4DlmG4dBxX42BmeL8IqFIPoZ4YSmeX0SV6RnqBLT4OL4Dm24V+w2vchkQONCyiM
         AidQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references;
        bh=7MN1030302t70DeNGRrKyHcA7xhfX6ZTmVDiGJN+8Rk=;
        b=SMKYMsZFqjaZimX0r2ypHd8k6dOLOvC3JBiZaEz0VX4AFZ0vb2xvM+O2N4j4SZD2EB
         7Qesui+oezJNkr8EZJL05EauhkRX08NTvqql+yDjD3CvU17zv+pByXF5Kkdey2syNN6w
         rgGXymKrC4/3Tn+gmg9ZFm80Zet1+ivBu8SYWmEAq1UpE2CuGoNcDGOUR0qh+7kfCs1Z
         br6GFVP33/VP6X8ROUOnu1CylUuSnPhH6uox4yHu8RFnqNSBNzK8XpqKHsiqZxGDnX0i
         CCHs0RKCR4zAUsgXZtIQy+M1muGDoIiUxm4UTGjYzr6uXKL8+d5CfO681FXUtwdeXZFC
         LgpA==
X-Gm-Message-State: APjAAAWZqDMBRgJoMlzDCtra3pOjHCDEMK6/QG9NrGwgL7FfxkYnvIGA
        oXeQnTsb5DrwQb0Yrci8TVJbwMcyZKo=
X-Google-Smtp-Source: 
 APXvYqyee7MJ9kmNN3EJ/pnZCGYkjM9KxJhKHhPshX5cWG15GDUuqjzISE+GtOB8gGV/gkvcfcIjFA==
X-Received: by 2002:a17:902:681:: with SMTP id
 1mr16673493plh.31.1552968288144;
        Mon, 18 Mar 2019 21:04:48 -0700 (PDT)
Received: from surajjs2.ozlabs.ibm.com ([122.99.82.10])
        by smtp.gmail.com with ESMTPSA id
 h87sm27650935pfj.20.2019.03.18.21.04.45
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Mon, 18 Mar 2019 21:04:47 -0700 (PDT)
From: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
To: kvm-ppc@vger.kernel.org
Cc: paulus@samba.org, kvm@vger.kernel.org,
        Suraj Jitindar Singh <sjitindarsingh@gmail.com>
Subject: [PATCH 2/3] KVM: PPC: Book3S HV: Implement virtual mode H_PAGE_INIT
 handler
Date: Tue, 19 Mar 2019 15:04:34 +1100
Message-Id: <20190319040435.10716-2-sjitindarsingh@gmail.com>
X-Mailer: git-send-email 2.13.6
In-Reply-To: <20190319040435.10716-1-sjitindarsingh@gmail.com>
References: <20190319040435.10716-1-sjitindarsingh@gmail.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Implement a virtual mode handler for the H_CALL H_PAGE_INIT which can be
used to zero or copy a guest page. The page is defined to be 4k and must
be 4k aligned.

The in-kernel handler halves the time to handle this H_CALL compared to
handling it in userspace for a radix guest.

Signed-off-by: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
---
 arch/powerpc/kvm/book3s_hv.c | 39 +++++++++++++++++++++++++++++++++++++++
 1 file changed, 39 insertions(+)

diff --git a/arch/powerpc/kvm/book3s_hv.c b/arch/powerpc/kvm/book3s_hv.c
index 7179ea783f4f..fa29cc4900c2 100644
--- a/arch/powerpc/kvm/book3s_hv.c
+++ b/arch/powerpc/kvm/book3s_hv.c
@@ -883,6 +883,39 @@ static int kvmppc_copy_guest(struct kvm *kvm, gpa_t to, gpa_t from,
 	return 0;
 }
 
+static int kvmppc_h_page_init(struct kvm_vcpu *vcpu, unsigned long flags,
+			      unsigned long dest, unsigned long src)
+{
+	int ret = H_FUNCTION;
+	u64 pg_sz = 1UL << 12;	/* 4K page size */
+	u64 pg_mask = pg_sz - 1;
+
+	/* Check for invalid flags (H_PAGE_SET_LOANED covers all CMO flags) */
+	if (flags & ~(H_ICACHE_INVALIDATE | H_ICACHE_SYNCHRONIZE |
+		      H_ZERO_PAGE | H_COPY_PAGE | H_PAGE_SET_LOANED))
+		return H_PARAMETER;
+
+	/* dest (and src if copy_page flag set) must be page aligned */
+	if ((dest & pg_mask) || ((flags & H_COPY_PAGE) && (src & pg_mask)))
+		return H_PARAMETER;
+
+	/* zero and/or copy the page as determined by the flags */
+	if (flags & H_ZERO_PAGE) {
+		ret = kvm_clear_guest(vcpu->kvm, dest, pg_sz);
+		if (ret < 0)
+			return H_PARAMETER;
+	}
+	if (flags & H_COPY_PAGE) {
+		ret = kvmppc_copy_guest(vcpu->kvm, dest, src, pg_sz);
+		if (ret < 0)
+			return H_PARAMETER;
+	}
+
+	/* We can ignore the remaining flags */
+
+	return H_SUCCESS;
+}
+
 static int kvm_arch_vcpu_yield_to(struct kvm_vcpu *target)
 {
 	struct kvmppc_vcore *vcore = target->arch.vcore;
@@ -1083,6 +1116,11 @@ int kvmppc_pseries_do_hcall(struct kvm_vcpu *vcpu)
 		if (nesting_enabled(vcpu->kvm))
 			ret = kvmhv_copy_tofrom_guest_nested(vcpu);
 		break;
+	case H_PAGE_INIT:
+		ret = kvmppc_h_page_init(vcpu, kvmppc_get_gpr(vcpu, 4),
+					 kvmppc_get_gpr(vcpu, 5),
+					 kvmppc_get_gpr(vcpu, 6));
+		break;
 	default:
 		return RESUME_HOST;
 	}
@@ -1127,6 +1165,7 @@ static int kvmppc_hcall_impl_hv(unsigned long cmd)
 	case H_IPOLL:
 	case H_XIRR_X:
 #endif
+	case H_PAGE_INIT:
 		return 1;
 	}
 

From patchwork Tue Mar 19 04:04:35 2019
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: 7bit
X-Patchwork-Submitter: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
X-Patchwork-Id: 10858815
Return-Path: <kvm-owner@kernel.org>
Received: from mail.wl.linuxfoundation.org (pdx-wl-mail.web.codeaurora.org
 [172.30.200.125])
	by pdx-korg-patchwork-2.web.codeaurora.org (Postfix) with ESMTP id 3D1D117E9
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:54 +0000 (UTC)
Received: from mail.wl.linuxfoundation.org (localhost [127.0.0.1])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id 24A8C29289
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:54 +0000 (UTC)
Received: by mail.wl.linuxfoundation.org (Postfix, from userid 486)
	id 18D7129453; Tue, 19 Mar 2019 04:04:54 +0000 (UTC)
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on
	pdx-wl-mail.web.codeaurora.org
X-Spam-Level: 
X-Spam-Status: No, score=-8.0 required=2.0 tests=BAYES_00,DKIM_SIGNED,
	DKIM_VALID,DKIM_VALID_AU,FREEMAIL_FROM,MAILING_LIST_MULTI,RCVD_IN_DNSWL_HI
	autolearn=ham version=3.3.1
Received: from vger.kernel.org (vger.kernel.org [209.132.180.67])
	by mail.wl.linuxfoundation.org (Postfix) with ESMTP id C2FC629289
	for <patchwork-kvm@patchwork.kernel.org>;
 Tue, 19 Mar 2019 04:04:52 +0000 (UTC)
Received: (majordomo@vger.kernel.org) by vger.kernel.org via listexpand
        id S1727463AbfCSEEw (ORCPT
        <rfc822;patchwork-kvm@patchwork.kernel.org>);
        Tue, 19 Mar 2019 00:04:52 -0400
Received: from mail-pg1-f195.google.com ([209.85.215.195]:40956 "EHLO
        mail-pg1-f195.google.com" rhost-flags-OK-OK-OK-OK) by vger.kernel.org
        with ESMTP id S1727174AbfCSEEv (ORCPT <rfc822;kvm@vger.kernel.org>);
        Tue, 19 Mar 2019 00:04:51 -0400
Received: by mail-pg1-f195.google.com with SMTP id u9so12904762pgo.7;
        Mon, 18 Mar 2019 21:04:51 -0700 (PDT)
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=gmail.com; s=20161025;
        h=from:to:cc:subject:date:message-id:in-reply-to:references;
        bh=Ekp0jAMs34yDRYCpAWNxtrr4EzeZ5eQ0pPK+waECduo=;
        b=dIFCDUjG1J7vTqqWU2Na/1yD4XoaGqYNfIIYjrIXbTKT7kgaK/afK8tSfmHgp6fylV
         rpg2iOojy6Kt3jKxp/OccWn6vD0cttpjiPVkh5QnEU4zw3nDTJ+uLF53+HLESauTR6Fp
         DB5ZJCK2QD0ryJ28eGd5BlxZ/h/a82tfLcIHimKJR/o+64UR5/0n84gcUQloAJxqbBUo
         e8oFX32V6a0j/XbPLL+wx92I8Rz46a0gB7fEbuavlU8La51FHBc0+BR4SINxKF/ccbL2
         UsE9RB4qNR4b6iz+uLeMTOoujLfH39UekA+JXpVZl6E2eXPWh080+Xyqjak+T8d1NWA9
         ppkQ==
X-Google-DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=1e100.net; s=20161025;
        h=x-gm-message-state:from:to:cc:subject:date:message-id:in-reply-to
         :references;
        bh=Ekp0jAMs34yDRYCpAWNxtrr4EzeZ5eQ0pPK+waECduo=;
        b=kl7LVEhyYjBPRdYcl6GR5A54tnCebJw6eoH4xfMS93Kn+cPibmd7KQooKy4Z3KVGkz
         z/gP1JbqNErkR6vimgKpWXWh7fQ/1aulwS9yYP1kUf/kTHkHAAyK77Ma/C8KAWduSOoW
         cUvZeo+0CuY2p7yKmh8vpxA4pS64jv8mDpBuXyT2zkSxg+wTvJs80rtdO6dtMUXmMfH0
         5o4B9gZP7qCJFCkgAj4QsbmwnWiKJ0LhAVNmM2g4kgtSwhtjLXtB8sWxVWXxKBdu0w25
         xNrrMvcQQ00P5MrgISFValN9j2ok3CN0ifNPaNM8PjuE/4dx2ggBtUsMU5eghLFW+45G
         v+SQ==
X-Gm-Message-State: APjAAAWI6f1JUvYVpNOWDJMk/MUwkpcfVoy7GOq/8ZrGIv5ADDS5bUOr
        h2g2ZAM2MHicvDa/77KZqybp5O6hJUg=
X-Google-Smtp-Source: 
 APXvYqzCsUT5ypFFwA5Yb605O+gVlkH6SqK6Pazkkdd+wl+GZDk/RsSTUXKmuI4ba50DcMtR44Ghuw==
X-Received: by 2002:a65:5c01:: with SMTP id u1mr20991450pgr.197.1552968290603;
        Mon, 18 Mar 2019 21:04:50 -0700 (PDT)
Received: from surajjs2.ozlabs.ibm.com ([122.99.82.10])
        by smtp.gmail.com with ESMTPSA id
 h87sm27650935pfj.20.2019.03.18.21.04.48
        (version=TLS1_2 cipher=ECDHE-RSA-CHACHA20-POLY1305 bits=256/256);
        Mon, 18 Mar 2019 21:04:50 -0700 (PDT)
From: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
To: kvm-ppc@vger.kernel.org
Cc: paulus@samba.org, kvm@vger.kernel.org,
        Suraj Jitindar Singh <sjitindarsingh@gmail.com>
Subject: [PATCH 3/3] KVM: PPC: Book3S HV: Implement real mode H_PAGE_INIT
 handler
Date: Tue, 19 Mar 2019 15:04:35 +1100
Message-Id: <20190319040435.10716-3-sjitindarsingh@gmail.com>
X-Mailer: git-send-email 2.13.6
In-Reply-To: <20190319040435.10716-1-sjitindarsingh@gmail.com>
References: <20190319040435.10716-1-sjitindarsingh@gmail.com>
Sender: kvm-owner@vger.kernel.org
Precedence: bulk
List-ID: <kvm.vger.kernel.org>
X-Mailing-List: kvm@vger.kernel.org
X-Virus-Scanned: ClamAV using ClamSMTP

Implement a real mode handler for the H_CALL H_PAGE_INIT which can be
used to zero or copy a guest page. The page is defined to be 4k and must
be 4k aligned.

The in-kernel real mode handler halves the time to handle this H_CALL
compared to handling it in userspace for a hash guest.

Signed-off-by: Suraj Jitindar Singh <sjitindarsingh@gmail.com>
---
 arch/powerpc/include/asm/kvm_ppc.h      |   2 +
 arch/powerpc/kvm/book3s_hv_rm_mmu.c     | 144 ++++++++++++++++++++++++++++++++
 arch/powerpc/kvm/book3s_hv_rmhandlers.S |   2 +-
 3 files changed, 147 insertions(+), 1 deletion(-)

diff --git a/arch/powerpc/include/asm/kvm_ppc.h b/arch/powerpc/include/asm/kvm_ppc.h
index 8e8bb1299a0e..f34f290463aa 100644
--- a/arch/powerpc/include/asm/kvm_ppc.h
+++ b/arch/powerpc/include/asm/kvm_ppc.h
@@ -653,6 +653,8 @@ long kvmppc_h_clear_ref(struct kvm_vcpu *vcpu, unsigned long flags,
                         unsigned long pte_index);
 long kvmppc_h_clear_mod(struct kvm_vcpu *vcpu, unsigned long flags,
                         unsigned long pte_index);
+long kvmppc_rm_h_page_init(struct kvm_vcpu *vcpu, unsigned long flags,
+			   unsigned long dest, unsigned long src);
 long kvmppc_hpte_hv_fault(struct kvm_vcpu *vcpu, unsigned long addr,
                           unsigned long slb_v, unsigned int status, bool data);
 unsigned long kvmppc_rm_h_xirr(struct kvm_vcpu *vcpu);
diff --git a/arch/powerpc/kvm/book3s_hv_rm_mmu.c b/arch/powerpc/kvm/book3s_hv_rm_mmu.c
index 3b3791ed74a6..26cfe1480ff5 100644
--- a/arch/powerpc/kvm/book3s_hv_rm_mmu.c
+++ b/arch/powerpc/kvm/book3s_hv_rm_mmu.c
@@ -867,6 +867,150 @@ long kvmppc_h_clear_mod(struct kvm_vcpu *vcpu, unsigned long flags,
 	return ret;
 }
 
+static int kvmppc_get_hpa(struct kvm_vcpu *vcpu, unsigned long gpa,
+			  int writing, unsigned long *hpa,
+			  struct kvm_memory_slot **memslot_p)
+{
+	struct kvm *kvm = vcpu->kvm;
+	struct kvm_memory_slot *memslot;
+	unsigned long gfn, hva, pa, psize = PAGE_SHIFT;
+	unsigned int shift;
+	pte_t *ptep, pte;
+
+	/* Find the memslot for this address */
+	gfn = gpa >> PAGE_SHIFT;
+	memslot = __gfn_to_memslot(kvm_memslots_raw(kvm), gfn);
+	if (!memslot || (memslot->flags & KVM_MEMSLOT_INVALID))
+		return H_PARAMETER;
+
+	/* Translate to host virtual address */
+	hva = __gfn_to_hva_memslot(memslot, gfn);
+
+	/* Try to find the host pte for that virtual address */
+	ptep = __find_linux_pte(vcpu->arch.pgdir, hva, NULL, &shift);
+	if (!ptep)
+		return H_TOO_HARD;
+	pte = kvmppc_read_update_linux_pte(ptep, writing);
+	if (!pte_present(pte))
+		return H_TOO_HARD;
+
+	/* Convert to a physical address */
+	if (shift)
+		psize = 1UL << shift;
+	pa = pte_pfn(pte) << PAGE_SHIFT;
+	pa |= hva & (psize - 1);
+	pa |= gpa & ~PAGE_MASK;
+
+	if (hpa)
+		*hpa = pa;
+	if (memslot_p)
+		*memslot_p = memslot;
+
+	return H_SUCCESS;
+}
+
+static int kvmppc_do_h_page_init_zero(struct kvm_vcpu *vcpu, unsigned long dest)
+{
+	struct kvm *kvm = vcpu->kvm;
+	struct kvm_memory_slot *memslot;
+	unsigned long pa;
+	unsigned long mmu_seq;
+	int i, ret = H_SUCCESS;
+
+	/* Used later to detect if we might have been invalidated */
+	mmu_seq = kvm->mmu_notifier_seq;
+	smp_rmb();
+
+	ret = kvmppc_get_hpa(vcpu, dest, 1, &pa, &memslot);
+	if (ret != H_SUCCESS)
+		return ret;
+
+	/* Check if we've been invalidated */
+	spin_lock(&kvm->mmu_lock);
+	if (mmu_notifier_retry(kvm, mmu_seq)) {
+		ret = H_TOO_HARD;
+		goto out_unlock;
+	}
+
+	/* Zero the page */
+	for (i = 0; i < 4096; i += L1_CACHE_BYTES, pa += L1_CACHE_BYTES)
+		dcbz((void *)pa);
+	kvmppc_update_dirty_map(memslot, dest >> PAGE_SHIFT, PAGE_SIZE);
+
+out_unlock:
+	spin_unlock(&kvm->mmu_lock);
+	return ret;
+}
+
+static int kvmppc_do_h_page_init_copy(struct kvm_vcpu *vcpu, unsigned long dest,
+				      unsigned long src)
+{
+	struct kvm *kvm = vcpu->kvm;
+	struct kvm_memory_slot *dest_memslot;
+	unsigned long dest_pa, src_pa;
+	unsigned long mmu_seq;
+	int ret = H_SUCCESS;
+
+	/* Used later to detect if we might have been invalidated */
+	mmu_seq = kvm->mmu_notifier_seq;
+	smp_rmb();
+
+	ret = kvmppc_get_hpa(vcpu, dest, 1, &dest_pa, &dest_memslot);
+	if (ret != H_SUCCESS)
+		return ret;
+	ret = kvmppc_get_hpa(vcpu, src, 0, &src_pa, NULL);
+	if (ret != H_SUCCESS)
+		return ret;
+
+	/* Check if we've been invalidated */
+	spin_lock(&kvm->mmu_lock);
+	if (mmu_notifier_retry(kvm, mmu_seq)) {
+		ret = H_TOO_HARD;
+		goto out_unlock;
+	}
+
+	/* Copy the page */
+	memcpy((void *)dest_pa, (void *)src_pa, 4096);
+
+	kvmppc_update_dirty_map(dest_memslot, dest >> PAGE_SHIFT, PAGE_SIZE);
+
+out_unlock:
+	spin_unlock(&kvm->mmu_lock);
+	return ret;
+}
+
+long kvmppc_rm_h_page_init(struct kvm_vcpu *vcpu, unsigned long flags,
+			   unsigned long dest, unsigned long src)
+{
+	struct kvm *kvm = vcpu->kvm;
+	u64 pg_sz = 1UL << 12;  /* 4K page size */
+	u64 pg_mask = pg_sz - 1;
+	int ret = H_SUCCESS;
+
+	/* Don't handle radix mode here, go up to the virtual mode handler */
+	if (kvm_is_radix(kvm))
+		return H_TOO_HARD;
+
+	/* Check for invalid flags (H_PAGE_SET_LOANED covers all CMO flags) */
+	if (flags & ~(H_ICACHE_INVALIDATE | H_ICACHE_SYNCHRONIZE |
+		      H_ZERO_PAGE | H_COPY_PAGE | H_PAGE_SET_LOANED))
+		return H_PARAMETER;
+
+	/* dest (and src if copy_page flag set) must be page aligned */
+	if ((dest & pg_mask) || ((flags & H_COPY_PAGE) && (src & pg_mask)))
+		return H_PARAMETER;
+
+	/* zero and/or copy the page as determined by the flags */
+	if (flags & H_ZERO_PAGE)
+		ret = kvmppc_do_h_page_init_zero(vcpu, dest);
+	if (flags & H_COPY_PAGE)
+		ret = kvmppc_do_h_page_init_copy(vcpu, dest, src);
+
+	/* We can ignore the other flags */
+
+	return ret;
+}
+
 void kvmppc_invalidate_hpte(struct kvm *kvm, __be64 *hptep,
 			unsigned long pte_index)
 {
diff --git a/arch/powerpc/kvm/book3s_hv_rmhandlers.S b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
index 9b8d50a7cbaf..5927497e7bbf 100644
--- a/arch/powerpc/kvm/book3s_hv_rmhandlers.S
+++ b/arch/powerpc/kvm/book3s_hv_rmhandlers.S
@@ -2268,7 +2268,7 @@ hcall_real_table:
 	.long	DOTSYM(kvmppc_rm_h_put_tce) - hcall_real_table
 	.long	0		/* 0x24 - H_SET_SPRG0 */
 	.long	DOTSYM(kvmppc_h_set_dabr) - hcall_real_table
-	.long	0		/* 0x2c */
+	.long	DOTSYM(kvmppc_rm_h_page_init) - hcall_real_table
 	.long	0		/* 0x30 */
 	.long	0		/* 0x34 */
 	.long	0		/* 0x38 */
